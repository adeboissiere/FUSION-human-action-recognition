{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset exploration for max-min coordinates boundaries\n",
    "\n",
    "\n",
    "A common normalization is to perform a dataset-wise min-max step for the skeleton joint coordinates. Our strategy is to first translate the camera coordinates to a new coordinate system. This new coordinate system corresponds to the center of the main subject's body. After performing this prior normalization, we calculate the min and max values across all joints, subjects and sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from src.utils.joints import *\n",
    "\n",
    "# Global variables (change depending on your setup)\n",
    "project_dir = os.getcwd() + '/../'\n",
    "h5_dataset_path = project_dir + \"/data/processed/\"\n",
    "skeleton_dataset_file_name = \"skeleton.h5\"\n",
    "log_file_name = \"samples_names.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Open h5 skeleton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all sample names (56 880)\n",
    "samples_names_list = [line.rstrip('\\n') for line in open(h5_dataset_path + log_file_name)]\n",
    "\n",
    "# Open dataset\n",
    "dataset = h5py.File(h5_dataset_path + skeleton_dataset_file_name, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate min-max coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_min : -4.766\n",
      "c_max : 5.1879997\n"
     ]
    }
   ],
   "source": [
    "# Loop through dataset to find c_min and c_max (see VA-LSTM/CNN paper for details)\n",
    "\n",
    "c_min = []\n",
    "c_max = []\n",
    "\n",
    "for sample_name in samples_names_list:\n",
    "    # Retrieve np array\n",
    "    skeleton = dataset[sample_name][\"skeleton\"][:]  # shape (3, max_frame, num_joint=25, 2)\n",
    "    \n",
    "    # Perform normalization step\n",
    "    trans_vector = skeleton[:, 0, Joints.SPINEMID, :] # shape (3, 2)\n",
    "    trans_vector[:, 1] = trans_vector[:, 0]\n",
    "    skeleton = (skeleton.transpose(1, 2, 0, 3) - trans_vector).transpose(2, 0, 1, 3)\n",
    "    \n",
    "    # Update c_min and c_max\n",
    "    c_min.append(np.amin(skeleton))\n",
    "    c_max.append(np.amax(skeleton))\n",
    "\n",
    "print(\"c_min : \" + str(np.amin(c_min)))\n",
    "print(\"c_max : \" + str(np.amax(c_max)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
